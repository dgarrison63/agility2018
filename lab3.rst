Section 3: Container Connector in Action
========================================

This section of the lab will cover creating OpenShift resources that the F5 Container Connector will process and use to updates the BIG-IP configuration

In a previous module, you deployed the F5 Container Connector in to the OpenShift cluster.  The Container Connector watches for events being generated by the Openshift API server
and takes action when it sees an OpenShift ConfigMap or Route resource that has an F5-specific label defined.

In the following exercises, we will create the following OpenShift resource types:

* ConfigMaps
* Routes

Additionally, we will also create variations of each resource type

ConfigMap - Basic
------------------

An OpenShift ConfigMap is one of the resource types that the F5 Container Connector watches for.    The Container Connector will read the ConfigMap
and create a virtual server, node(s), a pool, pool member(s) and a pool health monitor.

In this exercise, we will create a ConfigMap that defines the objects that the Container Connector should configure on the BIG-IP.

To complete this exercise, we will perform the following steps:

* Step 1: Deploy a demo application
* Step 2: Create a service to expose the demo application
* Step 3: Create a ConfigMap that declares desired BIG-IP configuration
* Step 4: Review the BIG-IP configuration


**Step 1**: Deploy demo application

From ose-master, review the following deployment -> demo-app.yaml

.. code-block:: console

    apiVersion: extensions/v1beta1
    kind: Deployment
    metadata:
    name: f5demo
    spec:
    replicas: 3
    template:
        metadata:
        labels:
            app: f5demo
            tier: frontend
        spec:
        containers:
        - name: f5demo
            image: kmunson1973/f5demo:1.0.0
            ports:
            - containerPort: 8080


**Step 2:** Create service to expose application

In order for an application to be accessible outside of the OpenShift cluster, a service must be created.  The service uses a label selector to reference the application to be exposed.
Additionally, the service also specifies the container port that the application is listening on.

From ose-master, review the following deployment: demo-app-service.yaml

.. code-block:: console

    apiVersion: v1
    kind: Service
    metadata:
    name: f5demo
    labels:
        app: f5demo
        tier: frontend
    spec:
    ports:
    - port: 8080
    selector:
        app: f5demo
        tier: frontend

Now that we have reviewed the Service, we need to actually create the Service by deploying it to OpenShift by using the "oc create" command:

.. code-block:: console

    [root@ose-mstr01 garrison]# oc create -f app-route.yaml
    route "front-end-route" created



**Step 3:** Create ConfigMap

A ConfigMap is used to define the BIG-IP objects that need to be created to enable access to the application via the BIG-IP.
The ConfigMap below defines a virtual server (frontend), pool (backend) and health monitor (healthMonitor).  Additionally, the ConfigMap references the service
created above in step #2.

The label, **f5type: virtual-server**, in the ConfigMap definition is what triggers the F5 Container Connector to process this ConfigMap.

**ConfigMap** points to a  **Service** which points to **Pod(s)** associated with the application

From ose-master, review the following deployment: demo-app-configmap.yaml

.. code-block:: console

    kind: ConfigMap
    apiVersion: v1
    metadata:
    # name of the resource to create on the BIG-IP
    name: myfronted-http.vs
    # The namespace to create the object in.
    # The k8s-bigip-ctlr watches all namespaces by default (as of v1.1).
    # If the k8s-bigip-ctlr is watching a specific namespace(s),
    # this setting must match the namespace of the Service you want to proxy
    # -AND- the namespace(s) the k8s-bigip-ctlr watches.
    namespace: f5demo
    labels:
        # tells the k8s-bigip-ctlr to watch this ConfigMap
        f5type: virtual-server
    data:
    # NOTE: schema v0.1.4 is required as of k8s-bigip-ctlr v1.3.0
    schema: "f5schemadb://bigip-virtual-server_v0.1.7.json"
    data: |
        {
        "virtualServer": {
            "backend": {
            "servicePort": 8080,
            "serviceName": "f5demo",
            "healthMonitors": [{
                "interval": 5,
                "protocol": "http",
                "send": "GET /\r\n",
                "timeout": 16
            }]
            },
            "frontend": {
            "virtualAddress": {
                "port": 80,
                "bindAddr": "10.10.202.200"
            },
            "partition": "ocp",
            "balance": "least-connections-node",
            "mode": "http"
            }
        }
        }



Now that we have reviewed the ConfigMap, we need to actually create the ConfigMap by deploying it to OpenShift by using the "oc create" command:

.. code-block:: console

    [root@ose-mstr01 garrison]# oc create -f bigip-vs-configmap.yaml
    configmap "vs-sock-shop" created



**Step 4:** Review BIG-IP configuration

TODO


Route - Basic
------------------

An OpenShift Route is one of the resource types that the F5 Container Connector watches for.  A Route defines a hostname or URI mapping to an application.  For example, the hostname "customer.example.com" could map
to the application "customer", hostname "catalog.example.com", might map to the application "catalog", etc.

Similarily, a Route can refer to a URI path so, for example, the URI path "/customer" might map to the application called "customer" and URI path "/catalog",
might map to the application called "catalog".  If a Route only specifies URI paths, the Route applies to all HTTP request hostnames.

Additionally, a Route can refer to both a hostname and a URI path.  So, for example, the 

The F5 Container Connector reads the Route resource and creates a virtual server, node(s), a pool per route path and pool members.  Additionally, the Container Connector
creates a layer 7 BIG-IP traffic policy and associates it with the virtual server.  This layer 7 traffic policy evaluates the hostname or URI path from the request and
forwards the traffic to the pool associated with that path.

**Route** points to a **Service(s)** which points to **Pod(s)** associated with the application

.. NOTE:: 

    All Route resources share two virtual servers:

    * **ose-vserver** for HTTP traffic, and
    * **https-ose-vserver** for HTTPS traffic

    The Container Connector assigns the names shown above by default. To set set custom names, define route-http-vserver and route-https-vserver in the BIG-IP Container Connector Deployment.
    Please see the documentation at: http://clouddocs.f5.com for more details.


To complete this exercise, we will perform the following steps:

* Step 1: Deploy a demo application
* Step 2: Create a service to expose the demo application
* Step 3: Create a ConfigMap that declares desired BIG-IP configuration
* Step 4: Review the BIG-IP configuration

**Step 1:** Deploy demo application


From ose-master, review the following deployment: app-deployment.yaml

.. code-block:: console

    "kind": "List"
    "apiVersion": "v1"
    "metadata": {}
    "items":
    - "kind": "DeploymentConfig"
        "apiVersion": "v1"
        "metadata":
            "name": "my-frontend"
            "creationTimestamp": null
            "labels":
            "app": "my-frontend"
        "spec":
        "strategy":
            "resources":
        "triggers":
            - "type": "ConfigChange"
        "replicas": 1
        "test": false
        "selector":
            "app": "my-frontend"
        "template":
            "metadata":
            "creationTimestamp": null
            "labels":
                "app": "my-frontend"
            "spec":
            "containers":
                - "name": "my-frontend"
                "image": "chen23/f5-demo-app:openshift"
                "ports":
                    - "containerPort": 8080
                    "protocol": "TCP"
        "status":
    - "kind": "Service"
        "apiVersion": "v1"
        "metadata":
        "name": "my-frontend"
        "creationTimestamp": null
        "labels":
            "app": "my-frontend"
        "spec":
        "ports":
            - "name": "8080-tcp"
            "protocol": "TCP"
            "port": 8080
            "targetPort": 8080
        "selector":
            "app": "my-frontend"
        "status":
        "loadBalancer":


Now that we have reviewed the Deployment, we need to actually create it by deploying it to OpenShift by using the "oc create" command:

.. code-block:: console

    root@ose-mstr01 garrison]# oc create -f app-deployment.yaml
    deploymentconfig "my-frontend" created
    service "my-frontend" created



**Step 2:** Create OpenShift Route

From ose-master, review the following deployment: demo-app-route.yaml


.. code-block:: console

    apiVersion: v1
    kind: Route
    metadata:
    labels:
        name: front-end-route
    name: front-end-route
    namespace: f5demo
    annotations:
        # Specify a supported BIG-IP load balancing mode
        virtual-server.f5.com/balance: least-connections-node
        virtual-server.f5.com/health: |
        [
            {
            "path": "mysite.f5demo.com/",
            "send": "HTTP GET /",
            "interval": 5,
            "timeout": 10
            }
        ]
    spec:
    host: mysite.f5demo.com
    path: "/"
    port:
        targetPort: 80
    to:
        kind: Service
        name: front-end


Now that we have reviewed the Route, we need to actually create it by deploying it to OpenShift by using the "oc create" command:

.. code-block:: console

    [root@ose-mstr01 garrison]# oc create -f app-route.yaml
    route "my-frontend-route-unsecured" created


**Step 3:** Review BIG-IP configuration

TODO



Route - A/B Testing
-------------------

The F5 Container Connector supports application A/B application testing e.g two different versions of the same application, by using the **weight** parameter of OpenShift Routes.  The **weight** parameter allows you
to establish relative ratios between application "A" and application "B". So, for example, if the first route specifies a weight of 20 and the second a weight of 10,
the application associated with the first route will get twice the number of connections as the application associated with the second route.

Just as in the previous excercise, the F5 Container Connector reads the Route resource and creates a virtual server, node(s), a pool per route path and pool members.  Additionally, the Container Connector
creates a layer 7 BIG-IP traffic policy and associates it with the virtual server.  This layer 7 traffic policy evaluates the hostname or URI path from the request and
forwards the traffic to the pool associated with that path.

However, in order to support A/B testing using OpenShift routes, the Container Connector creates an iRule on the BIG-IP which handles the connection routing based on the assigned weights.

To complete this exercise, we will perform the following steps:

* Step 1: Deploy version 1 of the application
* Step 2: Deploy version 2 of the application
* Step 3: Create an OpenShift Route with two paths that defines the weight for each application
* Step 4: Review BIG-IP configuration


**Step 1:** Deploy version 1 of the demo application

From ose-master, review the following deployment: app-deployment-ab-v1.yaml

.. code-block:: console

    "kind": "List"
    "apiVersion": "v1"
    "metadata": {}
    "items":
    - "kind": "DeploymentConfig"
        "apiVersion": "v1"
        "metadata":
            "name": "my-frontend-ab-v1"
            "creationTimestamp": null
            "labels":
            "app": "my-frontend-ab-v1"
        "spec":
        "strategy":
            "resources":
        "triggers":
            - "type": "ConfigChange"
        "replicas": 1
        "test": false
        "selector":
            "app": "my-frontend-ab-v1"
        "template":
            "metadata":
            "creationTimestamp": null
            "labels":
                "app": "my-frontend-ab-v1"
            "spec":
            "containers":
                - "name": "my-frontend-ab-v1"
                "image": "chen23/f5-demo-app:openshift"
                "ports":
                    - "containerPort": 8080
                    "protocol": "TCP"
        "status":
    - "kind": "Service"
        "apiVersion": "v1"
        "metadata":
        "name": "my-frontend-ab-v1"
        "creationTimestamp": null
        "labels":
            "app": "my-frontend-ab-v1"
        "spec":
        "ports":
            - "name": "8080-tcp"
            "protocol": "TCP"
            "port": 8080
            "targetPort": 8080
        "selector":
            "app": "my-frontend-ab-v1"
        "status":
        "loadBalancer":


Now that we have reviewed the Deployment, we need to actually create it by deploying it to OpenShift by using the "oc create" command:

.. code-block:: console

    [root@ose-mstr01 garrison]# oc create -f app-deployment-ab-v1.yaml
    deploymentconfig "my-frontend-ab-v1" created
    service "my-frontend-ab-v1" created


**Step 2:** Deploy version 2 of the demo application

From ose-master, review the following deployment: app-deployment-ab-v2.yaml

.. code-block:: console

    "kind": "List"
    "apiVersion": "v1"
    "metadata": {}
    "items":
    - "kind": "DeploymentConfig"
        "apiVersion": "v1"
        "metadata":
            "name": "my-frontend-ab-v2"
            "creationTimestamp": null
            "labels":
            "app": "my-frontend-ab-v2"
        "spec":
        "strategy":
            "resources":
        "triggers":
            - "type": "ConfigChange"
        "replicas": 1
        "test": false
        "selector":
            "app": "my-frontend-ab-v2"
        "template":
            "metadata":
            "creationTimestamp": null
            "labels":
                "app": "my-frontend-ab-v2"
            "spec":
            "containers":
                - "name": "my-frontend-ab-v2"
                "image": "chen23/f5-demo-app:openshift"
                "ports":
                    - "containerPort": 8080
                    "protocol": "TCP"
        "status":
    - "kind": "Service"
        "apiVersion": "v1"
        "metadata":
        "name": "my-frontend-ab-v2"
        "creationTimestamp": null
        "labels":
            "app": "my-frontend-ab-v2"
        "spec":
        "ports":
            - "name": "8080-tcp"
            "protocol": "TCP"
            "port": 8080
            "targetPort": 8080
        "selector":
            "app": "my-frontend-ab-v2"
        "status":
        "loadBalancer":


Now that we have reviewed the Deployment, we need to actually create it by deploying it to OpenShift by using the "oc create" command:

.. code-block:: console

    [root@ose-mstr01 garrison]# oc create -f app-deployment-ab-v2.yaml
    deploymentconfig "my-frontend-ab-v2" created
    service "my-frontend-ab-v2" created


**Step 3:** Create OpenShift Route for A/B testing

The basic Route example from the previous excercise only included one path.  In order to support A/B application testing, a Route must be created that has two paths.
In OpenShift, the second path is defined in the **alternateBackends** section of a Route resource.

From ose-master, review the following Route: app-route-ab.yaml

.. code-block:: console

    apiVersion: v1
    kind: Route
    metadata:
    labels:
        name: my-frontend-route-ab
    name: my-frontend-route-ab-unsecured
    namespace: f5demo
    annotations:
        # Specify a supported BIG-IP load balancing mode
        virtual-server.f5.com/balance: least-connections-node
        virtual-server.f5.com/health: |
        [
            {
            "path": "mysite-ab.f5demo.com/",
            "send": "HTTP GET /",
            "interval": 5,
            "timeout": 10
            }
        ]
    spec:
    host: mysite-ab.f5demo.com
    path: "/"
    port:
        targetPort: 8080
    to:
        kind: Service
        name: my-frontend-ab-v1
        weight: 20
    alternateBackends:
    - kind: Service
        name: my-frontend-ab-v2
        weight: 10


Now that we have reviewed the Route, we need to actually create it by deploying it to OpenShift by using the "oc create" command:

.. code-block:: console

    [root@ose-mstr01 garrison]# oc create -f app-route-ab.yaml
    route "my-frontend-route-ab-unsecured" created

Verify that the Route was successfully creating by using the OpenShift "oc get route" command.  Note that, under the "SERVICES" column, the two applications are listed along with their request distribution percentages.

.. code-block:: console

    [root@ose-mstr01 garrison]# oc get route
    NAME                             HOST/PORT              PATH      SERVICES                                        PORT      TERMINATION   WILDCARD
    my-frontend-route-ab-unsecured   mysite-ab.f5demo.com   /         my-frontend-ab-v1(66%),my-frontend-ab-v2(33%)   8080                    None


**Step 4:** Review BIG-IP configuration

TODO